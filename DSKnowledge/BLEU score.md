---
aliases: [Bilingual Evaluation Understudy]
---

The __BLEU score__ is a metric to evaluate the performance of [[Machine Translation]] models.

Original paper:

- _BLEU: a Method for Automatic Evaluation of Machine Translation_. 2002. [pdf](https://www.aclweb.org/anthology/P02-1040.pdf)