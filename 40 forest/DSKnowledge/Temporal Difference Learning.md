__Temporal Difference Learning__ is a class of model-free [[Reinforcement Learning]] methods which learn by bootstrapping from the current estimate of the value function.

They feel like a sort of enhanced [[Monte Carlo]] method in the sense that they update predictions as they keep sampling.

- [Wikipedia](https://en.wikipedia.org/wiki/Temporal_difference_learning).